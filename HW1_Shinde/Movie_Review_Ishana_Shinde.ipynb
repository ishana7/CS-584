{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie Review - Ishana Shinde.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCQ_LrRHl5Ld"
      },
      "source": [
        "Assignment 1 :\n",
        "Movie Review Classification using KNN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CImHi9oqmLYA"
      },
      "source": [
        "1. Import Libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKDFoe_hz8i2",
        "outputId": "417a56f7-dbad-469a-d05c-fed1d3db7d98"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import *\n",
        "from nltk.stem.porter import *\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIwQOJljmSku"
      },
      "source": [
        "2. Open the Train Data file and Remove Punctuations and Special Characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FgbVqQh3EaV"
      },
      "source": [
        "# Cleaning the train data.\n",
        "\n",
        "Train_data = open(\"train_new.csv\")  #opens the train file as csv\n",
        "train_lines = Train_data.readlines() # readlines from the csv file so we get the csv file with both ratings and reviews.\n",
        "\n",
        "stop_words = set(stopwords.words('english')) #stop_words is a set function that contains all stop words. Efficient for searching.\n",
        "\n",
        "\n",
        "Movie_ratings = [] # list that will contain all the movie ratings from the train data file.\n",
        "Train_Movie_reviews = [] # list that will contain all the movie reviews from the train data file.\n",
        "Train_Cleaned_Movie_Review = [] # list that will contain the cleaned and processed reviews from train data.\n",
        "\n",
        "\n",
        "\n",
        "clean_data = lambda x: re.sub(re.compile('<.*?>|[^\\w+\\']|[0-9]'), ' ', x) # removes all the punctuations, numbers, html tags and replaces them with space\n",
        "clean_data_special = lambda x: re.sub(re.compile('[^\\w\\s+]'), '', x) # removes all whitespaces and spaces within the text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for line in train_lines:                     # reads line from the file.\n",
        "  split_line = line.lower().rsplit('\\t')  # makes the entire line lowercase and splits each line based on tab.\n",
        "  Movie_ratings.append(split_line[0]) # takes the first element of the array and appends it to movie ratings list\n",
        "  Train_Movie_reviews.append(split_line[1]) # takes the second element of the array and appends it to movie reviews list.\n",
        "  Train_Unclean_Movie_reviews = split_line[1] # assigning the second element of the array to variable Train_Unclean_Movie_reviews.\n",
        "  Train_Cleaned_Movie_Review.append(clean_data_special(clean_data(Train_Unclean_Movie_reviews.replace('#EOF','')))) # Pass the Train_Unclean_Movie_reviews to the cleaned data function to remove all the unwanted punctuations and spaces.\n",
        "\n",
        "\n",
        "dict = {\"Movie Ratings\":Movie_ratings, \"Movie Reviews\": Train_Movie_reviews, \"Cleaned data\": Train_Cleaned_Movie_Review} #created a dictionary of movie ratings, reviews and the cleaned data\n",
        "\n",
        "Train_df = pd.DataFrame(dict) # converted the dictionary to DataFrame.\n",
        "Train_df = Train_df.dropna() # drop the missing values in the DataFrame.\n",
        "Train_df = Train_df.reset_index(drop=True) # reset the indices of elements after removing missing values.\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdWzKaDSmhEo"
      },
      "source": [
        "3. Remove the Stop Words from Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwSSa-lubA6V"
      },
      "source": [
        "# function to remove all the stop words from the cleaned data.\n",
        "Train_df['Remove Stop Words'] = Train_df['Cleaned data'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WfVUreEmlDW"
      },
      "source": [
        "4. Using Lemmatization and POS Tagging\n",
        "\n",
        "---\n",
        "\n",
        "In this cell below it throws an error sometimes for that simply comment the !pip install pattern line at the top and run the cell again. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Sug7D96WpQxq",
        "outputId": "bb90c639-54d5-4121-c671-54d51ddaa9d4"
      },
      "source": [
        "#!pip install pattern\n",
        "import pattern\n",
        "from nltk.corpus import wordnet as wn\n",
        "from pattern.en import tag\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer() # Using WordNetLemmatizer to assign meaning to each word in the review.\n",
        "\n",
        "def pos_tag_text(text): # function for POS Tagging on which we will use our WordNetLemmatizer.\n",
        "    \n",
        "    def penn_to_wn_tags(pos_tag):\n",
        "        if pos_tag.startswith('J'):\n",
        "            return wn.ADJ\n",
        "        elif pos_tag.startswith('V'):\n",
        "            return wn.VERB\n",
        "        elif pos_tag.startswith('N'):\n",
        "            return wn.NOUN\n",
        "        elif pos_tag.startswith('R'):\n",
        "            return wn.ADV\n",
        "        else:\n",
        "            return None\n",
        "    \n",
        "    tagged_text = tag(text)\n",
        "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
        "                         for word, pos_tag in\n",
        "                         tagged_text]\n",
        "    return tagged_lower_text\n",
        "    \n",
        "# lemmatize text based on POS tags    \n",
        "def lemmatize_text(text):\n",
        "    pos_tagged_text = pos_tag_text(text)\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word, pos_tag) if pos_tag else word for word, pos_tag in pos_tagged_text]\n",
        "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
        "    return lemmatized_text\n",
        "\n",
        "Train_df['POS tagged'] = Train_df['Remove Stop Words'].apply(lemmatize_text)\n",
        "Train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie Ratings</th>\n",
              "      <th>Movie Reviews</th>\n",
              "      <th>Cleaned data</th>\n",
              "      <th>Remove Stop Words</th>\n",
              "      <th>POS tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+1</td>\n",
              "      <td>one of my all-time favorite so-laughably-lousy...</td>\n",
              "      <td>one of my all time favorite so laughably lousy...</td>\n",
              "      <td>one time favorite laughably lousy totally lova...</td>\n",
              "      <td>one time favorite laughably lousy totally lova...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>i had high hopes for this film, because i thou...</td>\n",
              "      <td>i had high hopes for this film  because i thou...</td>\n",
              "      <td>high hopes film thought clean shaven kerrigans...</td>\n",
              "      <td>high hop film think clean shaven kerrigans fir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>when this was released, i thought this was one...</td>\n",
              "      <td>when this was released  i thought this was one...</td>\n",
              "      <td>released thought one profane films ever made h...</td>\n",
              "      <td>release thought one profane film ever make how...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>i just watched this movie on starz. let me go ...</td>\n",
              "      <td>i just watched this movie on starz  let me go ...</td>\n",
              "      <td>watched movie starz let go things thought coul...</td>\n",
              "      <td>watched movie starz let go thing thought could...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>+1</td>\n",
              "      <td>i loved it so much that i bought the dvd and t...</td>\n",
              "      <td>i loved it so much that i bought the dvd and t...</td>\n",
              "      <td>loved much bought dvd novel time chemistry act...</td>\n",
              "      <td>love much buy dvd novel time chemistry actor i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Movie Ratings  ...                                         POS tagged\n",
              "0            +1  ...  one time favorite laughably lousy totally lova...\n",
              "1            -1  ...  high hop film think clean shaven kerrigans fir...\n",
              "2            -1  ...  release thought one profane film ever make how...\n",
              "3            -1  ...  watched movie starz let go thing thought could...\n",
              "4            +1  ...  love much buy dvd novel time chemistry actor i...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "NBynju78Cp45",
        "outputId": "18a8982a-644b-4bfc-c94e-0f71b8031339"
      },
      "source": [
        "Train_df['Split'] = [word_tokenize(line1) for line1 in Train_df['POS tagged']]\n",
        "Train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie Ratings</th>\n",
              "      <th>Movie Reviews</th>\n",
              "      <th>Cleaned data</th>\n",
              "      <th>Remove Stop Words</th>\n",
              "      <th>POS tagged</th>\n",
              "      <th>Split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>+1</td>\n",
              "      <td>one of my all-time favorite so-laughably-lousy...</td>\n",
              "      <td>one of my all time favorite so laughably lousy...</td>\n",
              "      <td>one time favorite laughably lousy totally lova...</td>\n",
              "      <td>one time favorite laughably lousy totally lova...</td>\n",
              "      <td>[one, time, favorite, laughably, lousy, totall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>i had high hopes for this film, because i thou...</td>\n",
              "      <td>i had high hopes for this film  because i thou...</td>\n",
              "      <td>high hopes film thought clean shaven kerrigans...</td>\n",
              "      <td>high hop film think clean shaven kerrigans fir...</td>\n",
              "      <td>[high, hop, film, think, clean, shaven, kerrig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>when this was released, i thought this was one...</td>\n",
              "      <td>when this was released  i thought this was one...</td>\n",
              "      <td>released thought one profane films ever made h...</td>\n",
              "      <td>release thought one profane film ever make how...</td>\n",
              "      <td>[release, thought, one, profane, film, ever, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>i just watched this movie on starz. let me go ...</td>\n",
              "      <td>i just watched this movie on starz  let me go ...</td>\n",
              "      <td>watched movie starz let go things thought coul...</td>\n",
              "      <td>watched movie starz let go thing thought could...</td>\n",
              "      <td>[watched, movie, starz, let, go, thing, though...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>+1</td>\n",
              "      <td>i loved it so much that i bought the dvd and t...</td>\n",
              "      <td>i loved it so much that i bought the dvd and t...</td>\n",
              "      <td>loved much bought dvd novel time chemistry act...</td>\n",
              "      <td>love much buy dvd novel time chemistry actor i...</td>\n",
              "      <td>[love, much, buy, dvd, novel, time, chemistry,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>+1</td>\n",
              "      <td>it was a doubly interesting experience. for so...</td>\n",
              "      <td>it was a doubly interesting experience  for so...</td>\n",
              "      <td>doubly interesting experience reason greatest ...</td>\n",
              "      <td>doubly interesting experience reason great sci...</td>\n",
              "      <td>[doubly, interesting, experience, reason, grea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>-1</td>\n",
              "      <td>wow what a great premise for a film : set it a...</td>\n",
              "      <td>wow what a great premise for a film   set it a...</td>\n",
              "      <td>wow great premise film set around film maker w...</td>\n",
              "      <td>wow great premise film set around film maker w...</td>\n",
              "      <td>[wow, great, premise, film, set, around, film,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>-1</td>\n",
              "      <td>a lot of death happens in the wild. you don't ...</td>\n",
              "      <td>a lot of death happens in the wild  you dont n...</td>\n",
              "      <td>lot death happens wild dont need rocket scient...</td>\n",
              "      <td>lot death happen wild dont need rocket scienti...</td>\n",
              "      <td>[lot, death, happen, wild, dont, need, rocket,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>+1</td>\n",
              "      <td>corean cinema can be quite surprising for an o...</td>\n",
              "      <td>corean cinema can be quite surprising for an o...</td>\n",
              "      <td>corean cinema quite surprising occidental audi...</td>\n",
              "      <td>corean cinema quite surprising occidental audi...</td>\n",
              "      <td>[corean, cinema, quite, surprising, occidental...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>+1</td>\n",
              "      <td>running man isn't a great movie, in fact it's ...</td>\n",
              "      <td>running man isnt a great movie  in fact its ki...</td>\n",
              "      <td>running man isnt great movie fact kinda silly ...</td>\n",
              "      <td>run man isnt great movie fact kinda silly deli...</td>\n",
              "      <td>[run, man, isnt, great, movie, fact, kinda, si...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Movie Ratings  ...                                              Split\n",
              "0                +1  ...  [one, time, favorite, laughably, lousy, totall...\n",
              "1                -1  ...  [high, hop, film, think, clean, shaven, kerrig...\n",
              "2                -1  ...  [release, thought, one, profane, film, ever, m...\n",
              "3                -1  ...  [watched, movie, starz, let, go, thing, though...\n",
              "4                +1  ...  [love, much, buy, dvd, novel, time, chemistry,...\n",
              "...             ...  ...                                                ...\n",
              "24995            +1  ...  [doubly, interesting, experience, reason, grea...\n",
              "24996            -1  ...  [wow, great, premise, film, set, around, film,...\n",
              "24997            -1  ...  [lot, death, happen, wild, dont, need, rocket,...\n",
              "24998            +1  ...  [corean, cinema, quite, surprising, occidental...\n",
              "24999            +1  ...  [run, man, isnt, great, movie, fact, kinda, si...\n",
              "\n",
              "[25000 rows x 6 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klSQ9MBimsB_"
      },
      "source": [
        "5. Read the Test Data file and remove punctuations and special characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "P4KOHV5JCyu6",
        "outputId": "963f66e4-9608-4d8d-b5ac-40cfddc977a7"
      },
      "source": [
        "Test_data = open(\"1629732045_8755195_test_new.txt\", \"r\")\n",
        "test_lines = Test_data.readlines()\n",
        "\n",
        "Test_Movie_Reviews=[]\n",
        "Test_Cleaned_Movie_Review=[]\n",
        "\n",
        "clean_data = lambda x: re.sub(re.compile('<.*?>|[^\\w+\\']|[0-9]'), ' ', x)\n",
        "clean_data_special = lambda x: re.sub(re.compile('[^\\w\\s+]'), '', x)\n",
        "\n",
        "for line in test_lines:\n",
        "  split_line = line.lower().rsplit('\\t')\n",
        "  Test_Movie_Reviews.append(split_line[0])\n",
        "  Test_Unclean_Movie_reviews = split_line[0] \n",
        "  Test_Cleaned_Movie_Review.append(clean_data_special(clean_data(Test_Unclean_Movie_reviews.replace('#EOF',''))))\n",
        "\n",
        "\n",
        "dict = {\"Movie Reviews\": Test_Movie_Reviews, \"Cleaned data\": Test_Cleaned_Movie_Review}\n",
        "Test_df = pd.DataFrame(dict)\n",
        "Test_df = Test_df.dropna()\n",
        "Test_df = Test_df.reset_index(drop=True)\n",
        "Test_df.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie Reviews</th>\n",
              "      <th>Cleaned data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is a very low budget film, set in one loc...</td>\n",
              "      <td>this is a very low budget film  set in one loc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one minute into the untold and it`s already ri...</td>\n",
              "      <td>one minute into the untold and it s already ri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i recently purchased this on dvd as i hadn't h...</td>\n",
              "      <td>i recently purchased this on dvd as i hadnt he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>some people have the ability to use only 3 neu...</td>\n",
              "      <td>some people have the ability to use only   neu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>as i've said in the title of this review, it p...</td>\n",
              "      <td>as ive said in the title of this review  it pa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Movie Reviews                                       Cleaned data\n",
              "0  this is a very low budget film, set in one loc...  this is a very low budget film  set in one loc...\n",
              "1  one minute into the untold and it`s already ri...  one minute into the untold and it s already ri...\n",
              "2  i recently purchased this on dvd as i hadn't h...  i recently purchased this on dvd as i hadnt he...\n",
              "3  some people have the ability to use only 3 neu...  some people have the ability to use only   neu...\n",
              "4  as i've said in the title of this review, it p...  as ive said in the title of this review  it pa..."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx0CL0ZPm4Un"
      },
      "source": [
        "6. Remove the stop words from the Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vcgzsmyFdlb"
      },
      "source": [
        "Test_df['Remove Stop Words'] = Test_df['Cleaned data'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "jy4hQ9srGufk",
        "outputId": "16e86db4-72ec-4889-f330-4d8d44f9a4d6"
      },
      "source": [
        "Test_df['POS tagged'] = Test_df['Remove Stop Words'].apply(lemmatize_text)\n",
        "Test_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie Reviews</th>\n",
              "      <th>Cleaned data</th>\n",
              "      <th>Remove Stop Words</th>\n",
              "      <th>POS tagged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is a very low budget film, set in one loc...</td>\n",
              "      <td>this is a very low budget film  set in one loc...</td>\n",
              "      <td>low budget film set one location valley shield...</td>\n",
              "      <td>low budget film set one location valley shield...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one minute into the untold and it`s already ri...</td>\n",
              "      <td>one minute into the untold and it s already ri...</td>\n",
              "      <td>one minute untold already ripped techniques bl...</td>\n",
              "      <td>one minute untold already rip technique blair ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i recently purchased this on dvd as i hadn't h...</td>\n",
              "      <td>i recently purchased this on dvd as i hadnt he...</td>\n",
              "      <td>recently purchased dvd hadnt heard like robert...</td>\n",
              "      <td>recently purchase dvd hadnt hear like robert c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>some people have the ability to use only 3 neu...</td>\n",
              "      <td>some people have the ability to use only   neu...</td>\n",
              "      <td>people ability use neurons one eating one brea...</td>\n",
              "      <td>people ability use neurons one eat one breathe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>as i've said in the title of this review, it p...</td>\n",
              "      <td>as ive said in the title of this review  it pa...</td>\n",
              "      <td>ive said title review pains say hitch reaches ...</td>\n",
              "      <td>ive say title review pain say hitch reach zeni...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Movie Reviews  ...                                         POS tagged\n",
              "0  this is a very low budget film, set in one loc...  ...  low budget film set one location valley shield...\n",
              "1  one minute into the untold and it`s already ri...  ...  one minute untold already rip technique blair ...\n",
              "2  i recently purchased this on dvd as i hadn't h...  ...  recently purchase dvd hadnt hear like robert c...\n",
              "3  some people have the ability to use only 3 neu...  ...  people ability use neurons one eat one breathe...\n",
              "4  as i've said in the title of this review, it p...  ...  ive say title review pain say hitch reach zeni...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "Q5k8rFxEHit9",
        "outputId": "6911f11e-33e1-4b92-ec9f-2cd6bdbb1ac1"
      },
      "source": [
        "Test_df['Split'] = [word_tokenize(line1) for line1 in Test_df['POS tagged']]\n",
        "Test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Movie Reviews</th>\n",
              "      <th>Cleaned data</th>\n",
              "      <th>Remove Stop Words</th>\n",
              "      <th>POS tagged</th>\n",
              "      <th>Split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is a very low budget film, set in one loc...</td>\n",
              "      <td>this is a very low budget film  set in one loc...</td>\n",
              "      <td>low budget film set one location valley shield...</td>\n",
              "      <td>low budget film set one location valley shield...</td>\n",
              "      <td>[low, budget, film, set, one, location, valley...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one minute into the untold and it`s already ri...</td>\n",
              "      <td>one minute into the untold and it s already ri...</td>\n",
              "      <td>one minute untold already ripped techniques bl...</td>\n",
              "      <td>one minute untold already rip technique blair ...</td>\n",
              "      <td>[one, minute, untold, already, rip, technique,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i recently purchased this on dvd as i hadn't h...</td>\n",
              "      <td>i recently purchased this on dvd as i hadnt he...</td>\n",
              "      <td>recently purchased dvd hadnt heard like robert...</td>\n",
              "      <td>recently purchase dvd hadnt hear like robert c...</td>\n",
              "      <td>[recently, purchase, dvd, hadnt, hear, like, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>some people have the ability to use only 3 neu...</td>\n",
              "      <td>some people have the ability to use only   neu...</td>\n",
              "      <td>people ability use neurons one eating one brea...</td>\n",
              "      <td>people ability use neurons one eat one breathe...</td>\n",
              "      <td>[people, ability, use, neurons, one, eat, one,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>as i've said in the title of this review, it p...</td>\n",
              "      <td>as ive said in the title of this review  it pa...</td>\n",
              "      <td>ive said title review pains say hitch reaches ...</td>\n",
              "      <td>ive say title review pain say hitch reach zeni...</td>\n",
              "      <td>[ive, say, title, review, pain, say, hitch, re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>this movie looked like the out-takes of the de...</td>\n",
              "      <td>this movie looked like the out takes of the de...</td>\n",
              "      <td>movie looked like takes deleted scenes high sc...</td>\n",
              "      <td>movie look like take delete scene high school ...</td>\n",
              "      <td>[movie, look, like, take, delete, scene, high,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>this is one of my three all-time favorite movi...</td>\n",
              "      <td>this is one of my three all time favorite movi...</td>\n",
              "      <td>one three time favorite movies quibble directo...</td>\n",
              "      <td>one three time favorite movie quibble director...</td>\n",
              "      <td>[one, three, time, favorite, movie, quibble, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>most families will recognise similarities betw...</td>\n",
              "      <td>most families will recognise similarities betw...</td>\n",
              "      <td>families recognise similarities family created...</td>\n",
              "      <td>family recognise similarity family create bril...</td>\n",
              "      <td>[family, recognise, similarity, family, create...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>i stumbled upon this movie by accident. i mean...</td>\n",
              "      <td>i stumbled upon this movie by accident  i mean...</td>\n",
              "      <td>stumbled upon movie accident mean else could f...</td>\n",
              "      <td>stumble upon movie accident mean else could fi...</td>\n",
              "      <td>[stumble, upon, movie, accident, mean, else, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>a scarily real drama, there isn't another dram...</td>\n",
              "      <td>a scarily real drama  there isnt another drama...</td>\n",
              "      <td>scarily real drama isnt another drama scared c...</td>\n",
              "      <td>scarily real drama isnt another drama scar cra...</td>\n",
              "      <td>[scarily, real, drama, isnt, another, drama, s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Movie Reviews  ...                                              Split\n",
              "0      this is a very low budget film, set in one loc...  ...  [low, budget, film, set, one, location, valley...\n",
              "1      one minute into the untold and it`s already ri...  ...  [one, minute, untold, already, rip, technique,...\n",
              "2      i recently purchased this on dvd as i hadn't h...  ...  [recently, purchase, dvd, hadnt, hear, like, r...\n",
              "3      some people have the ability to use only 3 neu...  ...  [people, ability, use, neurons, one, eat, one,...\n",
              "4      as i've said in the title of this review, it p...  ...  [ive, say, title, review, pain, say, hitch, re...\n",
              "...                                                  ...  ...                                                ...\n",
              "24995  this movie looked like the out-takes of the de...  ...  [movie, look, like, take, delete, scene, high,...\n",
              "24996  this is one of my three all-time favorite movi...  ...  [one, three, time, favorite, movie, quibble, d...\n",
              "24997  most families will recognise similarities betw...  ...  [family, recognise, similarity, family, create...\n",
              "24998  i stumbled upon this movie by accident. i mean...  ...  [stumble, upon, movie, accident, mean, else, c...\n",
              "24999  a scarily real drama, there isn't another dram...  ...  [scarily, real, drama, isnt, another, drama, s...\n",
              "\n",
              "[25000 rows x 5 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEpCLQjVJtAq"
      },
      "source": [
        "7. Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdNIPgqAJsCz"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(norm = 'l2')\n",
        "    \n",
        "train_matrix= vectorizer.fit_transform(Train_df['POS tagged'])\n",
        "test_matrix = vectorizer.transform(Test_df['POS tagged'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2jza1YIDL-W"
      },
      "source": [
        "8. K-Fold Cross Validation\n",
        "\n",
        "I used the K-Fold cross validation to check for what KNN-K value, I get approximate 50% accuracy. This Validation I implemented before my own implementation of KNN so for this I used the sklearn KNeighborsClassifier. Here I tried for different values of k and approximately for k = 341, I got 0.8056 accuracy and with the same k value for my Knn implementation I got a score of 0.79 on miner.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e8hWC4IY50I"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_matrix, Train_df['Movie Ratings'], test_size=0.3, random_state=123)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shrn1NfoUixx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc76a54-2253-4f30-fcd2-67c8852c49e3"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=341, metric='cosine')\n",
        "clf = neigh.fit(X_train, y_train)\n",
        "#clf = MultinomialNB().fit(X_train, y_train)\n",
        "predicted= clf.predict(X_test)\n",
        "print(\"KNN Accuracy:\",metrics.accuracy_score(y_test, predicted))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.8056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMG8UAFlpCia",
        "outputId": "d4a9d04e-4fae-46e1-99e6-f8cfce68a380"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "cv = KFold(n_splits=25, shuffle = True)\n",
        "X, y = make_classification(n_samples=450, n_features=7450, n_informative=15, n_redundant=5, random_state=1)\n",
        "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "max(scores)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm7ZZ8t2C_vb"
      },
      "source": [
        "8. KNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0pohwhOBzoR"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "import math\n",
        "\n",
        "\n",
        "similarities = cosine_similarity(test_matrix, train_matrix) # computes cosine similarity between the two as a numpy array\n",
        "\n",
        " \n",
        "\n",
        "def predict_neighbor(nearestNeighbors, labels): # Finds majority vote among the nearest neiighbors.\n",
        "    \n",
        "    total = 0\n",
        "    for neighbor in nearestNeighbors:\n",
        "      total += int(labels[neighbor])\n",
        "    if total > 0:\n",
        "      return 1\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "prediction_result = []\n",
        "\n",
        "def KNN(k): # implementation of KNN logic\n",
        "    \n",
        "    for similar in similarities:\n",
        "      knn = np.argsort(-similar)[:k]\n",
        "      prediction = predict_neighbor(knn, Train_df['Movie Ratings'])\n",
        "      if prediction == 1:\n",
        "        prediction_result.append('+1')\n",
        "      else:\n",
        "        prediction_result.append('-1')\n",
        "\n",
        "KNN(341)\n",
        "\n",
        "\n",
        "output_file = open('KNN_Prediction.txt', 'w')\n",
        "output_file.writelines( \"%s\\n\" % item for item in prediction_result )\n",
        "output_file.close()\n"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}